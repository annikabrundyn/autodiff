# autodiff 

[WIP]
this is a basic automatic differentiation library in python and numpy.

right now, this only works with scalars and is using forward mode AD.

TODOS:

- [ ] change to use reverse mode AD (instead of forward mode)
- [ ] extend to tensors not just scalars - requires jacobian vector product
- [ ] caching/memoization
- [ ] parallelization?
